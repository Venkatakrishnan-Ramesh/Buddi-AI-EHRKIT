<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?properties open_access?><?properties manuscript?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-journal-id">101603542</journal-id><journal-id journal-id-type="pubmed-jr-id">43479</journal-id><journal-id journal-id-type="nlm-ta">S Afr J Bioeth Law</journal-id><journal-id journal-id-type="iso-abbrev">S Afr J Bioeth Law</journal-id><journal-title-group><journal-title>South African journal of bioethics and law</journal-title></journal-title-group><issn pub-type="epub">1999-7639</issn></journal-meta><article-meta><article-id pub-id-type="pmc">PMC9439582</article-id><article-id pub-id-type="doi">10.7196/sajbl.2022.v15i1.797</article-id><article-id pub-id-type="manuscript">NIHMS1810718</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Artificial intelligence in healthcare: Proposals for policy development in South Africa</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Naidoo</surname><given-names>S</given-names></name><degrees>LLB</degrees></contrib><contrib contrib-type="author"><name><surname>Bottomley</surname><given-names>D</given-names></name><degrees>LLB</degrees></contrib><contrib contrib-type="author"><name><surname>Naidoo</surname><given-names>M</given-names></name><degrees>LLM</degrees></contrib><contrib contrib-type="author"><name><surname>Donnelly</surname><given-names>D</given-names></name><degrees>PhD</degrees></contrib><contrib contrib-type="author"><name><surname>Thaldar</surname><given-names>D W</given-names></name><degrees>PhD</degrees></contrib><aff id="A1">School of Law, College of Law and Management Studies, University of KwaZulu-Natal, Durban, South Africa</aff></contrib-group><author-notes><corresp id="CR1"><bold>Corresponding author:</bold> D Donnelly (<email>donnellyd@ukzn.ac.za</email>)</corresp><fn fn-type="con" id="FN1"><p id="P1"><bold>Author contributions.</bold> SN &#x02013; conceptualisation, project co-ordination, writing of original draft; DB &#x02013; conceptualisation, writing of original draft (liability); MN &#x02013; conceptualisation, writing of original draft (innovation and development); DD &#x02013; conceptualisation, revision, supervision; DT &#x02013; conceptualisation, revision, supervision, funding acquisition.</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>25</day><month>5</month><year>2022</year></pub-date><pub-date pub-type="ppub"><day>5</day><month>8</month><year>2022</year></pub-date><pub-date pub-type="epub"><day>19</day><month>5</month><year>2022</year></pub-date><pub-date pub-type="pmc-release"><day>02</day><month>9</month><year>2022</year></pub-date><volume>15</volume><issue>1</issue><fpage>11</fpage><lpage>16</lpage><permissions><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This open-access article is distributed under Creative Commons licence CC-BY-NC 4.0.</license-p></license></permissions><abstract id="ABS1"><p id="P2">Despite the tremendous promise offered by artificial intelligence (AI) for healthcare in South Africa, existing policy frameworks are inadequate for encouraging innovation in this field. Practical, concrete and solution-driven policy recommendations are needed to encourage the creation and use of AI systems. This article considers five distinct problematic issues which call for policy development: (<italic toggle="yes">i</italic>) outdated legislation; (<italic toggle="yes">ii</italic>) data and algorithmic bias; (<italic toggle="yes">iii</italic>) the impact on the healthcare workforce; (<italic toggle="yes">iv</italic>) the imposition of liability dilemma; and (<italic toggle="yes">v</italic>) a lack of innovation and development of AI systems for healthcare in South Africa. The adoption of a national policy framework that addresses these issues directly is imperative to ensure the uptake of AI development and deployment for healthcare in a safe, responsible and regulated manner.</p></abstract></article-meta></front><body><p id="P3">Artificial intelligence (AI) in healthcare is not a novel concept, as the application of such systems in medicine dates back to as early as the 1950s,<sup>[<xref rid="R1" ref-type="bibr">1</xref>]</sup> and pilot projects were deployed in Africa during the mid-1980s.<sup>[<xref rid="R2" ref-type="bibr">2</xref>]</sup> However, AI-enabled systems are currently transforming the healthcare sector at an unprecedented rate, through their use in evaluating the risk of disease onset and potential treatment outcomes, alleviating or reducing complications, ongoing patient care, clinical research and drug development.<sup>[<xref rid="R3" ref-type="bibr">3</xref>]</sup> The rapid growth of AI is due to quantum leaps in computing power, growth in the big-data phenomenon, significant investments in research and development of basic AI technologies.<sup>[<xref rid="R4" ref-type="bibr">4</xref>]</sup></p><p id="P4">AI-enabled systems can provide patients with increased access to better-quality healthcare while simultaneously reining in rising medical costs and making treatments more affordable.<sup>[<xref rid="R5" ref-type="bibr">5</xref>]</sup> For example, using Vantage&#x02019;s AI-powered software, Ugu Municipality in KwaZulu-Natal was the first district to achieve UNAID&#x02019;s 90-90-90 outcomes for HIV patient treatment adherence and monitoring.<sup>[<xref rid="R6" ref-type="bibr">6</xref>]</sup> More recently, a mobile app developed by Vantage was utilised for COVID-19 community screening in Mpumalanga Province.<sup>[<xref rid="R7" ref-type="bibr">7</xref>]</sup> Despite the tremendous potential offered by AI in transforming and improving healthcare in low-resource areas,<sup>[<xref rid="R8" ref-type="bibr">8</xref>]</sup> the development and deployment of such technologies gives rise to several important social, legal and ethical concerns. Therefore it is imperative that South Africa (SA) develops and implements appropriate policy and regulatory frameworks for the responsible use and governance of AI and data for healthcare<sup>[<xref rid="R9" ref-type="bibr">9</xref>]</sup> in order to truly harness the benefits promised by such technologies.</p><p id="P5">In September 2021, an online workshop was hosted by the University of KwaZulu-Natal (UKZN) School of Law on AI in healthcare in SA (&#x02018;the workshop&#x02019;).<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup> During the workshop, five distinct problematic issues called for policy development: (<italic toggle="yes">i</italic>) outdated legislation; (<italic toggle="yes">ii</italic>) data and algorithmic bias; (<italic toggle="yes">iii</italic>) impact on the healthcare workforce; (<italic toggle="yes">iv</italic>) imposition of liability dilemma; and (<italic toggle="yes">v</italic>) a lack of innovation and development of AI systems for healthcare in SA. In the present article, we provide a pragmatic, legal analysis of these five issues and make recommendations for policy development. This article also refers to the high-level ethics principles developed to guide policymaking in relation to AI on which there is robust, international discourse. We recognise that there should be a debate in SA on the extent to which these principles should be applied in, or adapted for, the SA context. This is not within the scope and purpose of the present article, but will be a fruitful area for future research.</p><sec id="S1"><title>Ethics principles for AI regulation</title><p id="P6">For the benefit of novice readers, in this section we include a brief overview of the emerging ethics principles relevant to the regulation of AI. In recent years, AI&#x02019;s ethical and social implications have attracted much attention from numerous public, private and non-governmental organisations, many of which have produced normative documents that comprise principles and guidance for ethical and socially responsible AI.<sup>[<xref rid="R11" ref-type="bibr">11</xref>]</sup> The sheer volume of principles put forth by such organisations threatens to become overwhelming and perplexing, with the potential development of a &#x02018;market for principles&#x02019; in which stakeholders cherry-pick those most beneficial for their purposes.<sup>[<xref rid="R12" ref-type="bibr">12</xref>]</sup> As a result, scholars have begun to analyse the content of these documents, identifying the extent to which a global consensus on AI ethics is emerging.<sup>[<xref rid="R11" ref-type="bibr">11</xref>]</sup> It is important to note that this &#x02018;global consensus&#x02019; does not incorporate a uniquely African perspective. Instead, the ethical stance of African countries is represented through their relation to international or supranational organisations who have produced normative documents.<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup> Therefore, the process of assimilating the normative values into a constitutionally and culturally appropriate and binding legal instrument in SA must still be undertaken, with care to heed the caution that there remain divergences in approach, interpretation and emphasis.<sup>[<xref rid="R11" ref-type="bibr">11</xref>]</sup> Nonetheless, for purposes of the present analysis, we emphasise that there is significant overlap between the principles put forward by these organisations. Interestingly, no single principle appears to be common to all documents. However, the results of different studies<sup>[<xref rid="R11" ref-type="bibr">11</xref>&#x02013;<xref rid="R14" ref-type="bibr">14</xref>]</sup> aimed at conceptually categorising ethics topics, and reducing them into a smaller number, are highly consistent.<sup>[<xref rid="R11" ref-type="bibr">11</xref>]</sup></p><p id="P7">The more extensive of these studies<sup>[<xref rid="R11" ref-type="bibr">11</xref>,<xref rid="R13" ref-type="bibr">13</xref>]</sup> identify five principles most frequently referenced across AI ethics documents, albeit with some differences in nomenclature, namely: (<italic toggle="yes">i</italic>) transparency; (<italic toggle="yes">ii</italic>) justice and fairness; (<italic toggle="yes">iii</italic>) non-maleficence; (<italic toggle="yes">iv</italic>) responsibility; and (<italic toggle="yes">v</italic>) privacy. The concepts considered below may be referred to as the &#x02018;normative core&#x02019; of a principle-based approach to AI ethics and governance.<sup>[<xref rid="R14" ref-type="bibr">14</xref>]</sup> The inclusion of all the principles that make up this normative core in more recent documents suggests that the conversation around AI ethics is beginning to converge.<sup>[<xref rid="R14" ref-type="bibr">14</xref>]</sup> However, navigating the sea of modern AI ethics documents requires a general understanding of this normative core, as these principles are sometimes articulated in different ways &#x02013; this will be illustrated with reference to the Organisation for Economic Co-operation and Development (OECD)&#x02019;s 2019 Recommendation of the Council on AI<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> and the UNESCO Recommendation on the ethics of AI.<sup>[<xref rid="R16" ref-type="bibr">16</xref>]</sup></p><sec id="S2"><title>Transparency</title><p id="P8">While this is the most prevalent principle in the current literature, there is significant variation in its articulation and interpretation.<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup> Most references to transparency comprise &#x02018;efforts to increase explainability, interpretability or other acts of communication and disclosure&#x02019;.<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup> It is presented as a way to &#x02018;minimise harm and improve AI&#x02019;<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup> through the requirement that systems be developed and deployed to allow for human oversight, including through &#x02018;translation of their operations into intelligible outputs and provision of information&#x02019; regarding their use.<sup>[<xref rid="R14" ref-type="bibr">14</xref>]</sup> The OECD articulates this principle as &#x02018;transparency and explainability&#x02019;, suggesting that AI actors should provide meaningful, context-appropriate information to foster a general understanding of AI systems; inform stakeholders and those affected by AI outcomes; and enable those adversely affected to challenge its outcome.<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> Similarly, UNESCO emphasises that transparency and explainability of AI systems is an essential component of a &#x02018;trustworthy&#x02019; AI system.<sup>[<xref rid="R16" ref-type="bibr">16</xref>]</sup></p></sec><sec id="S3"><title>Justice and fairness</title><p id="P9">Justice is primarily articulated in terms of calls for fairness<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup> encompassing both inclusive access to the benefits of AI technologies and the elimination of unfair discrimination, which may be perpetuated by bias in the datasets on which AI systems are trained.<sup>[<xref rid="R12" ref-type="bibr">12</xref>]</sup> At present, AI bias is already impacting individuals worldwide; therefore appeals for AI technologies to be designed and used to maximise fairness and promote inclusivity are articulated through fairness and non-discrimination principles.<sup>[<xref rid="R14" ref-type="bibr">14</xref>]</sup> In alignment with the general trend, the OECD articulates justice under the principle of &#x02018;human-centred values and fairness&#x02019; which states that throughout the lifecycle of the system, AI actors should uphold the rule of law, human rights and democratic values which includes, among others, non-discrimination and equality.<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> This appeal is reiterated under the banner &#x02018;Inclusive growth, sustainable development and well-being&#x02019; which suggests that AI actors should proactively ensure the inclusion of under-represented populations and the reduction of economic, social, gender and other inequalities.<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> The themes of inclusion and non-discrimination are given equally strong emphasis by UNESCO.<sup>[<xref rid="R16" ref-type="bibr">16</xref>]</sup></p></sec><sec id="S4"><title>Non-maleficence</title><p id="P10">This principle encompasses general calls for safety and security which stipulate that AI technologies perform as intended, should never cause foreseeable or unintentional harm, and are secured against access by unauthorised parties.<sup>[<xref rid="R14" ref-type="bibr">14</xref>]</sup> Interestingly, references to non-maleficence outweigh those to beneficence,<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup> with most organisations prioritising caution against the overuse or misuse of AI technologies which may lead to a plethora of negative consequences. The OECD explicitly asserts the principle of &#x02018;robustness, security and safety&#x02019;,<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> stating that &#x02018;AI systems should be robust, secure and safe throughout their entire lifecycle&#x02019; so that they function appropriately and do not pose unreasonable risks.<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> Guidelines for harm prevention most often focus on technical measures and governance strategies.<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup> In line with this tendency, the OECD suggest that AI actors &#x02018;apply a systematic risk management approach to each phase of the AI system lifecycle on a continuous basis&#x02019; to address any risks that may arise.<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> In the UNESCO recommendation, the principle of non-maleficence finds expression in the requirement to &#x02018;do no harm&#x02019; through implementation of proportionality (the choice of AI technologies that do not exceed what is appropriate and proportional to achieve a legitimate aim) and sustainability (the implementation of AI measures that benefit rather than hinder the realisation of social, cultural, economic and environmental sustainability objectives).<sup>[<xref rid="R16" ref-type="bibr">16</xref>]</sup></p></sec><sec id="S5"><title>Responsibility</title><p id="P11">While &#x02018;responsible AI&#x02019; is widely referenced, both responsibility and accountability are rarely defined in the literature.<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup> Responsibility and accountability recognise the importance of mechanisms that ensure that accountability (for harm caused by AI systems) &#x02018;is appropriately distributed, and that adequate remedies are provided.&#x02019;<sup>[<xref rid="R14" ref-type="bibr">14</xref>]</sup> AI developers, designers, institutions and &#x02018;industry&#x02019; are variously referenced as being responsible and accountable for decisions made and harm caused by AI systems.<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup> The OECD asserts this principle under the banner of &#x02018;accountability&#x02019;, which notes that AI actors should not only be accountable for the proper functioning of AI systems but also for ensuring respect of all the principles contained within the Recommendation.<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> The stated definition of AI actors is quite broad, encompassing all those &#x02018;who play an active role in the AI system lifecycle, including organisations and individuals that deploy or operate AI&#x02019;.<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> In the UNESCO recommendation, the scope of accountability is extended to require both AI actors and member states<sup>[<xref rid="R16" ref-type="bibr">16</xref>]</sup> to develop oversight, impact assessment, audit and due diligence mechanisms and whistle-blower protections.</p></sec><sec id="S6"><title>Privacy</title><p id="P12">Within the current literature, privacy is seen &#x02018;both as a value to uphold and as a right to be protected.&#x02019;<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup> It expresses the requirement that AI systems respect individual privacy both in the use of personal data for training algorithms and also by allowing for agency over individuals&#x02019; data and decisions made therefrom.<sup>[<xref rid="R14" ref-type="bibr">14</xref>]</sup> Interestingly, the OECD does not reference privacy as a stand-alone principle; instead, it is mentioned only via its relation to other principles. Under the principle &#x02018;human-centred values and fairness&#x02019;, it is recommended that AI actors should respect the rule of law, human rights and democratic values including those of privacy and data protection.<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> However, in the more recent UNESCO recommendation, the importance of privacy is underscored as being essential to human dignity, autonomy and agency.<sup>[<xref rid="R16" ref-type="bibr">16</xref>]</sup></p></sec></sec><sec id="S7"><title>Outdated legislation</title><p id="P13">SA does not currently have any specific laws in place that deal with AI, but may draw guidance from the UNESCO recommendation on the ethics of AI.<sup>[<xref rid="R16" ref-type="bibr">16</xref>]</sup> Further, as a member of the G20 policy development group, SA is guided by the G20 AI principles,<sup>[<xref rid="R17" ref-type="bibr">17</xref>]</sup> which are drawn from the OECD Recommendation of the Council on AI.<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup> Furthermore, AI applications developed for healthcare use in SA will have to comply with a range of national statutes. However, this legislative framework presents several barriers to the development and deployment of AI in healthcare.</p><p id="P14">One such barrier is found in the definition of &#x02018;medical device&#x02019;, as stated in the Medicines and Related Substances Act (the Act).<sup>[<xref rid="R18" ref-type="bibr">18</xref>]</sup> To fall within the ambit of the given definition, any machine or software must be intended by the manufacturer to be used in the diagnosis, treatment, monitoring or alleviation of any disease or injury, as well as in the prevention of any disease. General software, which is not specifically intended for such a purpose, will not be considered a medical device, even where it is used in a healthcare context.<sup>[<xref rid="R19" ref-type="bibr">19</xref>]</sup> This definition severely limits the use of AI in healthcare. This issue is particularly concerning when considering AI-enabled systems such as COVID-19 chatbots which provide symptom checking, reporting and exposure services and can have clear health implications when they incorrectly advise a patient.<sup>[<xref rid="R19" ref-type="bibr">19</xref>]</sup> A reconsideration, and subsequent widening, of the definition of medical device could help in the adoption and use of such technologies in a safe, responsible and regulated manner in line with AI ethics principles.</p><p id="P15">Currently, the Act provides for a single-stage model of regulatory review for medical devices, according to predefined static specifications and standards.<sup>[<xref rid="R19" ref-type="bibr">19</xref>]</sup> However, this traditional review process is unsuitable for &#x02018;unlocked&#x02019; AI systems which can &#x02018;adapt and optimise device performance in real-time&#x02019;,<sup>[<xref rid="R20" ref-type="bibr">20</xref>]</sup> through the use of big data analytics and machine learning. Thus, how the machine will respond to, and interpret, data may not be entirely predictable to physicians or patients.<sup>[<xref rid="R20" ref-type="bibr">20</xref>]</sup> To address this issue, the Food and Drug Administration (FDA) in the US has proposed a novel approach, termed the &#x02018;total product lifecycle (TPLC) regulatory approach&#x02019;.<sup>[<xref rid="R20" ref-type="bibr">20</xref>]</sup> This approach involves a multi-stage evaluation. It requires evaluation and monitoring of unlocked AI systems both at the pre-market and post-market stage.<sup>[<xref rid="R20" ref-type="bibr">20</xref>]</sup> This approach is expectedly more onerous on the manufacturer who is to provide more data and predictions regarding how the device may act going forward. However, given the risks involved in sectors such as healthcare, this approach may provide a regulatory solution for the risks that unlocked AI systems pose.</p></sec><sec id="S8"><title>Data and algorithmic bias</title><p id="P16">One of the workshop&#x02019;s main points of discussion focused on the quality of data used to train AI systems and the potentially biased outcomes that may arise therefrom. Biased data sets that do not accurately represent a model use case can result in the AI producing skewed outcomes. In general, training data for machine learning projects in the healthcare sector have to be representative of the real world.<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup> Where the data are not representative, this could lead to many problematic issues &#x02013; including injustice, discrimination, false diagnoses and even the possibility of rendering treatments ineffective which will in turn jeopardise patient safety.<sup>[<xref rid="R21" ref-type="bibr">21</xref>]</sup> The issue of non-representative data is further exacerbated in the SA context as invention and development of AI technologies mostly occurs outside our borders.<sup>[<xref rid="R22" ref-type="bibr">22</xref>]</sup> Thus, the data used to train these systems may not be representative of the SA population. However, it was noted in the workshop that while representative data is the way forward in eliminating bias, even where we are able to train AI healthcare systems on ideal high-quality data &#x02013; data which are accurate, complete, consistent, unique and timely &#x02013; we still see the perpetuation of discrimination or bias through existing structural inequalities in the form of algorithmic bias.<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup></p><p id="P17">A possible solution to the data and algorithmic bias problem is the establishment of an institution akin to the UK&#x02019;s Data Ethics and Innovation Centre, which deals with ethical issues related to AI, including the quality of input data to AI processes.<sup>[<xref rid="R23" ref-type="bibr">23</xref>]</sup> The Data Ethics and Innovation Centre&#x02019;s bias review programme focuses on investigating algorithmic bias across various sectors through literature review, technical research and public engagement workshops. The programme is aimed at producing recommendations to government about how any potential harms can be identified and minimised.<sup>[<xref rid="R24" ref-type="bibr">24</xref>]</sup></p><p id="P18">The South African Presidential Commission on the Fourth Industrial Revolution (4IR Commission) recommended the establishment of an AI Institute as one of SA&#x02019;s technological development plans.<sup>[<xref rid="R25" ref-type="bibr">25</xref>]</sup> While the AI Institute is intended to form part of all current and future global initiatives on AI, and to deal with ethical issues arising from the development and deployment of AI, its assigned powers and functions remain unclear. We recommend that a specific body be enacted that deals with the issues relating to bias or, alternatively, the AI Institute should have a specific mandate to create a programme within its structure that deals with this matter.</p></sec><sec id="S9"><title>Impact on workforce</title><p id="P19">In noting that AI is not meant to replace the work of physicians or other healthcare practitioners but rather to complement, facilitate and enhance human work, the workshop participants asserted that new technologies have an uncanny way of displacing and even deskilling workers.<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup> The right to work was recognised as a critical consideration for policy development around AI.<sup>[<xref rid="R21" ref-type="bibr">21</xref>]</sup></p><p id="P20">By the year 2030, the World Health Organization (WHO) has estimated, there will be a shortage of 18 million health workers &#x02013; mostly in lower- to middle-income countries (LMICs).<sup>[<xref rid="R26" ref-type="bibr">26</xref>]</sup> The WHO advocates AI to bridge the gap between the current and future deficit in healthcare workers and the ideal workforce required to provide appropriate healthcare.<sup>[<xref rid="R27" ref-type="bibr">27</xref>]</sup> In addition, the workshop participants expressed optimistic views in the understanding that AI will not take away but rather help in job creation.<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup></p><p id="P21">The workshop participants highlighted the need to initiate education and the incorporation of AI knowledge into the current healthcare system and workforce.<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup> Such initiatives are especially relevant in LMICs as local staff may have insufficient experience with information technology (IT) systems or electronic data management, and may have poor technological literacy.<sup>[<xref rid="R28" ref-type="bibr">28</xref>]</sup></p><p id="P22">Countries around the world seem to consider education to be a cornerstone in the uptake of AI. The Indian AI Taskforce Report released in March 2018 emphasised the need for change in the education curriculum and the need to reskill the labour force to ensure an AI-ready future.<sup>[<xref rid="R29" ref-type="bibr">29</xref>]</sup> In addition, the United Arab Emirates (UAE) government established an AI &#x02018;smart lab&#x02019; in 2017 to train employees in the public and private sectors to implement AI in their respective fields.<sup>[<xref rid="R23" ref-type="bibr">23</xref>]</sup></p><p id="P23">We suggest that the establishment of a similar education and reskilling programme in the SA healthcare context could encourage use and trust in AI-enabled systems. Such a programme may fall under the ambit of the AI Institute proposed by the 4IR Commission, which is responsible for ensuring capacity-building in AI.<sup>[<xref rid="R25" ref-type="bibr">25</xref>]</sup></p></sec><sec id="S10"><title>Imposing liability</title><p id="P24">SA, being the first and currently (at the time of writing) the only country to grant a patent listing an AI system as the inventor,<sup>[<xref rid="R30" ref-type="bibr">30</xref>]</sup> was a keen topic of discussion at the workshop. The crux of the debate focused on the implications that such a patent may have for the legal subjectivity and, subsequently, the legal liability of AI. Participants proposed that the granting of inventorship is the first prong in a &#x02018;slippery slope&#x02019; leading to the granting of AI legal subjectivity which, in turn, only provides for the creation of a legal loophole for companies, developers and users of AI systems to foist legal and financial responsibility.<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup></p><p id="P25">The possibility of developing company law as a model for AI liability was also scrutinised, as such a liability regime requires the ability to &#x02018;pierce the corporate veil&#x02019; and identify who is directing the company. It was proposed that such an undertaking would be impossible in the context of AI that operates autonomously, as opposed to a company which operates through decisions made by human beings.<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup></p><p id="P26">Additionally, SA common law imposes fault-based liability on the human healthcare practitioner, which entails that one may be held liable if one fails to meet the objectively measured standard expected of a reasonable practitioner in his/her branch of the profession. However, the use of AI systems raises the explicability or &#x02018;black box algorithm&#x02019; issue. This is so as the inner logic with which a machine reaches certain conclusions is arguably inscrutable to health practitioners or patients and makes it virtually impossible for practitioners to foresee and thus take reasonable steps to prevent an error and meet the required standard of care.<sup>[<xref rid="R19" ref-type="bibr">19</xref>]</sup> Furthermore, it is uncertain how a practitioner should proceed and maintain the required standard of care where an AI system, which is trained with far more data than a human could reasonably comprehend, recommends unconventional treatments. Crucially, the autonomous nature with which some of these AI systems operate also creates challenges in assigning fault. It is difficult to justify a finding of fault or negligence for a human from an AI decision, and yet it is also not currently possible to attribute liability to an AI system.</p><p id="P27">The WHO, in their 2021 report on the Ethics and Governance of AI for Health (&#x02018;the report&#x02019;), listed accountability as a key ethics principle.<sup>[<xref rid="R27" ref-type="bibr">27</xref>]</sup> Importantly, despite the challenges associated with establishing fault, as is often the case owing to the nature of the technology, the report firmly requires there to be human accountability &#x02013; either through sole, or joint and several, liability.<sup>[<xref rid="R27" ref-type="bibr">27</xref>]</sup> However, liability is not limited to the healthcare practitioner, but also the manufacturer. In the event that fault cannot be attributed to either party, then it could lie with &#x02018;the government agency or institution that selected, validated and deployed it&#x02019;.<sup>[<xref rid="R27" ref-type="bibr">27</xref>]</sup></p><p id="P28">In terms of remedies, the report notes that it will be desirable to have different types of possible redress including forms of compensation, rehabilitation, restitution and possible sanctions with guarantees of non-repetition from entities that develop and deploy AI health systems.<sup>[<xref rid="R27" ref-type="bibr">27</xref>]</sup> Collective responsibility is proposed to avoid the diffusion of responsibility and to encourage all those involved in the creation and use of AI to act with integrity and to minimise harm.<sup>[<xref rid="R27" ref-type="bibr">27</xref>]</sup></p><p id="P29">The use of fault-based legal liability regimes poses many issues when considering AI development and deployment in the healthcare context, and seems to be at odds with the understanding of accountability as put forward by the WHO in their report. One possible solution to this problem may lie in replacing the existing idea of liability, as based on the Western legal tradition, with a reconciliatory approach aligned with the African tradition &#x02013; particularly the concept of <italic toggle="yes">ubuntu</italic>, which has been described as &#x02018;foundational to the spirit of reconciliation and bridge-building&#x02019;.<sup>[<xref rid="R31" ref-type="bibr">31</xref>]</sup> Instead of focusing on questions such as &#x02018;Who acted?&#x02019; and &#x02018;Was the act wrongful?&#x02019;, which cause persons involved to be antagonistic and defensive, the focus should shift to learning how to better use AI in healthcare, and to actively developing guidelines for AI developers and healthcare professionals who are using AI systems. But how can this work in practice?</p><p id="P30">A model of what an &#x02018;AI in Healthcare Reconciliation Commission&#x02019; may look like can be drawn from the Commission for Conciliation, Mediation and Arbitration (CCMA),<sup>[<xref rid="R32" ref-type="bibr">32</xref>]</sup> the Truth and Reconciliation Commission (TRC)<sup>[<xref rid="R33" ref-type="bibr">33</xref>]</sup> and the Road Accident Fund (RAF),<sup>[<xref rid="R34" ref-type="bibr">34</xref>]</sup> all of which do not strictly adhere to traditional Western notions of fault-based legal liability. The basis for such a model may be discerned from the CCMA, the inception of which signalled a shift from &#x02018;a highly adversarial model of relations to one based on promoting greater co-operation, industrial peace and social justice&#x02019;.<sup>[<xref rid="R35" ref-type="bibr">35</xref>]</sup> Instead of litigation, disputes must be resolved inter alia through reconciliation. Given that AI technology is still in its infancy, society must learn from actual disputes and develop relevant, detailed legal rules accordingly. In this light, the TRC can also serve as a model. It held broad investigative powers, was able to insist on access to relevant information, and provided a platform for victims to share their stories in an attempt to make recommendations aimed at preventing such abuses in the future.<sup>[<xref rid="R36" ref-type="bibr">36</xref>]</sup></p><p id="P31">A critical element of the AI in Healthcare Reconciliation Commission is the introduction of an insurance scheme, akin to that of the RAF, to compensate victims for harm caused by AI systems in the healthcare setting. The RAF is responsible for rehabilitating and compensating injured persons, as well as actively promoting the safe use of SA roads.<sup>[<xref rid="R37" ref-type="bibr">37</xref>]</sup> In addition, the introduction of a mandatory insurance regime when considering AI civil liability has been proposed by the European Union (EU).<sup>[<xref rid="R38" ref-type="bibr">38</xref>]</sup> The proposal was based on the understanding that liability coverage is a key factor in the success of new technologies and is vital for ensuring that the public can trust new technologies.<sup>[<xref rid="R38" ref-type="bibr">38</xref>]</sup> Under such a regime, strict liability is imposed. In this way, the difficulties of assigning fault are avoided, while adequate victim compensation is assured.</p><p id="P32">While patients who suffer harm, in the context of the use of AI in healthcare, should be compensated, this does not mean that there should be a legal battle, or that specific persons ought to pay the compensation. We suggest that at these early stages of adopting such a qualitatively different, new technology &#x02013; AI &#x02013; it is more important for society to learn from past mistakes and to plot an informed path ahead. This will be optimised by excluding litigation in favour of reconciliation. Of course, as guidelines are gradually developed by the AI in Healthcare Reconciliation Commission, these can be enforced through professional bodies, and can inform legislation regarding the development and ongoing regulatory overview of AI in healthcare.</p></sec><sec id="S11"><title>Lack of innovation and development</title><p id="P33">The workshop unearthed the patenting activity within AI relating to SA. Although only an approximate measure, patents are an established and useful method to measure innovation,<sup>[<xref rid="R39" ref-type="bibr">39</xref>,<xref rid="R40" ref-type="bibr">40</xref>]</sup> and have been used as a proxy for the state of innovation in AI in SA.<sup>[<xref rid="R41" ref-type="bibr">41</xref>]</sup> The figures that were presented, however, did not reflect much optimism. During 2012 &#x02013; 2021, 9 231 AI patent applications listed SA as a designated country, yet there were just 10 AI patents filed from within SA itself.<sup>[<xref rid="R22" ref-type="bibr">22</xref>]</sup> As a possible solution to this, some believe that granting inventorship status to AI systems could result in a more enabling environment that promotes the development of complex cognitive and creative AI systems &#x02013; subject, of course, to human beings upstream being the actual owners of the patent.<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup></p><p id="P34">The question then becomes: How do we truly drive innovation in the AI and healthcare arena, since these technologies offer a solution to the resource and capacity constraints which SA is currently facing? One such solution may be found in the leveraging of a public-sector health data institution.</p><p id="P35">A serious obstacle to the uptake of the development of AI in Africa is the availability of data and the costs associated with its acquisition.<sup>[<xref rid="R2" ref-type="bibr">2</xref>]</sup> The National Digital Health Strategy for South Africa 2019 &#x02013; 2024 identifies the development of a patient electronic health record as a key priority.<sup>[<xref rid="R42" ref-type="bibr">42</xref>]</sup> Such a record system provides a sufficient amount of high-quality representative data with which to train AI systems. The standardised nature of the record also allows for alleviation of the significant investment and effort required to curate non-optimised data and to ensure its suitability for an AI system analysis.<sup>[<xref rid="R28" ref-type="bibr">28</xref>]</sup></p><p id="P36">Availing public sector data to develop, train and improve AI-enabled systems is not an unorthodox concept. The Declaration of Cooperation on Artificial Intelligence, which was ratified by 25 European countries in April 2018,<sup>[<xref rid="R43" ref-type="bibr">43</xref>]</sup> saw member states agree to ensure better access to public sector data in order to &#x02018;influence AI development, fuelling innovative business models and creating economic growth and new qualified jobs&#x02019;.<sup>[<xref rid="R43" ref-type="bibr">43</xref>]</sup></p><p id="P37">However, access to the sensitive health data of patients raises many privacy and security concerns. A robust legal framework or governance system for such data may be key to encouraging innovation, while simultaneously preserving the privacy and security of patients. A federated data system could be the solution to safeguarding against these concerns as data do not leave the participating organisation that holds them, but authorised individuals can access these data to train algorithms.<sup>[<xref rid="R27" ref-type="bibr">27</xref>]</sup></p><p id="P38">Where we can establish a public sector data institution alongside the proposed patient electronic record, allowing SA developers to access health data in a secure and safe manner that respects the rights of the patient, we can incentivise the development and deployment of AI for use in healthcare in SA.</p></sec><sec id="S12"><title>Conclusion</title><p id="P39">The potential of AI in healthcare is enumerated in the substantial body of research on the topic and several global, multilateral and national policy frameworks. National strategies for the use of AI in healthcare and the wider health system are currently being developed by numerous countries around the world.<sup>[<xref rid="R9" ref-type="bibr">9</xref>]</sup> These strategies typically feature the acknowledgement of a significant role played by governments in creating an enabling environment for the adoption and use of AI for the greater good of society.<sup>[<xref rid="R9" ref-type="bibr">9</xref>]</sup> Accordingly, it is imperative for the SA government to embrace this central role through the adoption of a national policy framework to ensure the uptake of AI development and deployment for healthcare in a safe, responsible and regulated manner.</p></sec></body><back><ack id="S13"><title>Funding.</title><p id="P40">The support of the HSRC/Facebook Ethics &#x00026; Human Rights and AI in Africa grant is gratefully acknowledged. We acknowledge the support of the US National Institute of Mental Health and the US National Institutes of Health (award number U01MH127690). The content of this article is solely our responsibility and does not necessarily represent the official views of the US National Institute of Mental Health or the US National Institutes of Health.</p></ack><fn-group><fn fn-type="COI-statement" id="FN2"><p id="P41"><bold>Conflict of interest.</bold> None.</p></fn></fn-group><ref-list><ref id="R1"><label>1.</label><mixed-citation publication-type="journal"><name><surname>Tran</surname><given-names>BX</given-names></name>, <name><surname>Vu</surname><given-names>GT</given-names></name>, <name><surname>Ha</surname><given-names>GH</given-names></name>, <etal/>
<article-title>Global evolution of research in artificial intelligence in health and medicine: A bibliometric study</article-title>. <source>J Clin Med</source>
<year>2019</year>;<volume>8</volume>(<issue>3</issue>):<fpage>360</fpage>. <pub-id pub-id-type="doi">10.3390/jcm8030360</pub-id></mixed-citation></ref><ref id="R2"><label>2.</label><mixed-citation publication-type="journal"><name><surname>Owoyemi</surname><given-names>AJ</given-names></name>, <name><surname>Boyd</surname><given-names>AD</given-names></name>. <article-title>Artificial intelligence for healthcare in Africa</article-title>. <source>Front Digit Health</source>
<year>2020</year>;<volume>2</volume>:<fpage>6</fpage>. <pub-id pub-id-type="doi">10.3389/fdgth.2020.00006</pub-id><pub-id pub-id-type="pmid">34713019</pub-id></mixed-citation></ref><ref id="R3"><label>3.</label><mixed-citation publication-type="journal"><name><surname>Becker</surname><given-names>A</given-names></name>. <article-title>Artificial intelligence in medicine: What is it doing for us today?</article-title>
<source>Health Policy Technol</source>
<year>2019</year>;<volume>8</volume>(<issue>2</issue>):<fpage>198</fpage>&#x02013;<lpage>205</lpage>. <pub-id pub-id-type="doi">10.1016/j.hlpt.2019.03.004</pub-id></mixed-citation></ref><ref id="R4"><label>4.</label><mixed-citation publication-type="webpage"><name><surname>Schoeman</surname><given-names>W</given-names></name>, <name><surname>Moore</surname><given-names>R</given-names></name>, <name><surname>Seedat</surname><given-names>Y</given-names></name>, <name><surname>Chen</surname><given-names>JY</given-names></name>. <source>Artificial intelligence: Is South Africa ready?</source>
<comment><ext-link xlink:href="https://accenture.com/_acnmedia/pdf-107/accenture-ai-south-africa-ready.pdf" ext-link-type="uri">https://accenture.com/_acnmedia/pdf-107/accenture-ai-south-africa-ready.pdf</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>30 September 2021</date-in-citation>).</mixed-citation></ref><ref id="R5"><label>5.</label><mixed-citation publication-type="webpage"><name><surname>Sallstrom</surname><given-names>L</given-names></name>, <name><surname>Morris</surname><given-names>O</given-names></name>, <name><surname>Mehta</surname><given-names>H</given-names></name>. <source>Artificial intelligence in Africa&#x02019;s healthcare: Ethical considerations</source>. <comment>ORF Issue Brief No. 312.</comment>
<year>2019</year>. <comment><ext-link xlink:href="https://orfonline.org/research/artificial-intelligence-in-africas-healthcare-ethical-considerations-55232/" ext-link-type="uri">https://orfonline.org/research/artificial-intelligence-in-africas-healthcare-ethical-considerations-55232/</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>30 September 2021</date-in-citation>).</mixed-citation></ref><ref id="R6"><label>6.</label><mixed-citation publication-type="webpage"><collab>USAID</collab>. <source>Vantage Software from USAID Partner BroadReach Spotlighted at Microsoft Conference</source>. <year>2021</year>. <comment><ext-link xlink:href="https://www.usaid.gov/global-health/health-areas/hiv-and-aids/information-center/news-and-updates/vantage-software-usaid-partner" ext-link-type="uri">https://www.usaid.gov/global-health/health-areas/hiv-and-aids/information-center/news-and-updates/vantage-software-usaid-partner</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>19 February 2022</date-in-citation>).</mixed-citation></ref><ref id="R7"><label>7.</label><mixed-citation publication-type="book"><collab>Broadreach Group</collab>. <source>Mpumalanga launches Vantage mobile app to stop Covid-19 spread</source>. <publisher-loc>Cape Town</publisher-loc>: <publisher-name>BroadReach</publisher-name>, <year>2020</year>. <comment><ext-link xlink:href="https://broadreachcorporation.com/together-we-will-conquer-mpumalanga-launches-mobile-app-to-stop-covid-19-spread/" ext-link-type="uri">https://broadreachcorporation.com/together-we-will-conquer-mpumalanga-launches-mobile-app-to-stop-covid-19-spread/</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>19 February 2022</date-in-citation>).</mixed-citation></ref><ref id="R8"><label>8.</label><mixed-citation publication-type="journal"><name><surname>Hoodbhoy</surname><given-names>Z</given-names></name>, <name><surname>Hasan</surname><given-names>B</given-names></name>, <name><surname>Siddiqui</surname><given-names>K</given-names></name>. <article-title>Does artificial intelligence have any role in healthcare in low resource settings?</article-title>
<source>J Med Artif Intell</source>
<year>2019</year>;<volume>2</volume>:<fpage>13</fpage>. <pub-id pub-id-type="doi">10.21037/jmai.2019.06.01</pub-id></mixed-citation></ref><ref id="R9"><label>9.</label><mixed-citation publication-type="webpage"><name><surname>Singh</surname><given-names>V</given-names></name>. <article-title>AI and data in South Africa&#x02019;s health sector</article-title>. <source>Pretoria: Policy Action Network</source>, <year>2020</year>. <comment><ext-link xlink:href="https://policyaction.org.za/sites/default/files/PAN_TopicalGuide_AIData6_Health_Elec.pdf" ext-link-type="uri">https://policyaction.org.za/sites/default/files/PAN_TopicalGuide_AIData6_Health_Elec.pdf</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>4 October 2021</date-in-citation>).</mixed-citation></ref><ref id="R10"><label>10.</label><mixed-citation publication-type="book"><collab>University of KwaZulu-Natal</collab>. <source>Virtual workshop: Artificial intelligence in healthcare in South Africa</source>. <publisher-loc>Durban</publisher-loc>: <publisher-name>UKZN</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="https://law.ukzn.ac.za/virtual-workshop-artificial-intelligence-in-healthcare-in-south-africa/" ext-link-type="uri">https://law.ukzn.ac.za/virtual-workshop-artificial-intelligence-in-healthcare-in-south-africa/</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>14 October 2021</date-in-citation>).</mixed-citation></ref><ref id="R11"><label>11.</label><mixed-citation publication-type="journal"><name><surname>Schiff</surname><given-names>D</given-names></name>, <name><surname>Borenstein</surname><given-names>J</given-names></name>, <name><surname>Biddle</surname><given-names>J</given-names></name>, <etal/>
<article-title>AI ethics in the public, private, and NGO sectors: A review of a global document collection</article-title>. <source>IEEE Transactions on Technology and Society</source>
<year>2021</year>;<volume>2</volume>(<issue>1</issue>):<fpage>31</fpage>&#x02013;<lpage>42</lpage>. <pub-id pub-id-type="doi">10.1109/TTS.2021.3052127</pub-id></mixed-citation></ref><ref id="R12"><label>12.</label><mixed-citation publication-type="journal"><name><surname>Floridi</surname><given-names>L</given-names></name>, <name><surname>Cowls</surname><given-names>J</given-names></name>. <article-title>A unified framework of five principles for AI in society</article-title>. <source>Harvard Data Sci Rev</source>
<year>2019</year>;<volume>1</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1162/99608f92.8cd550d1</pub-id></mixed-citation></ref><ref id="R13"><label>13.</label><mixed-citation publication-type="journal"><name><surname>Jobin</surname><given-names>A</given-names></name>, <name><surname>Ienca</surname><given-names>M</given-names></name>, <name><surname>Vayena</surname><given-names>E</given-names></name>. <article-title>The global landscape of AI ethical guidelines</article-title>. <source>Nat Mach Intell</source>
<year>2019</year>;<volume>1</volume>:<fpage>389</fpage>&#x02013;<lpage>399</lpage>. <pub-id pub-id-type="doi">10.1038/s42256-019-0088-2</pub-id></mixed-citation></ref><ref id="R14"><label>14.</label><mixed-citation publication-type="book"><name><surname>Fjeld</surname><given-names>J</given-names></name>, <name><surname>Achten</surname><given-names>N</given-names></name>, <etal/>
<source>Principled artificial intelligence: Mapping consensus in ethical and rights-based approaches to principles for AI</source>. <publisher-name>Berkman Klein Centre for Internet &#x00026; Society</publisher-name>, <year>2020</year>. <comment><ext-link xlink:href="https://cyber.harvard.edu/publication/2020/principled-ai" ext-link-type="uri">https://cyber.harvard.edu/publication/2020/principled-ai</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>17 May 2022</date-in-citation>).</mixed-citation></ref><ref id="R15"><label>15.</label><mixed-citation publication-type="book"><collab>Organisation for Economic Co-operation and Development</collab>. <source>Recommendation of the Council on Artificial Intelligence</source>. <publisher-loc>Paris</publisher-loc>: <publisher-name>OECD</publisher-name>, <year>2019</year>. <comment><ext-link xlink:href="https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449" ext-link-type="uri">https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>19 February 2022</date-in-citation>).</mixed-citation></ref><ref id="R16"><label>16.</label><mixed-citation publication-type="book"><collab>United Nations Educational, Scientific and Cultural Organization</collab>. <source>Recommendations on the Ethics of Artificial Intelligence</source>. <publisher-loc>Paris</publisher-loc>: <publisher-name>UNESCO</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="https://unesdoc.unesco.org/ark:/48223/pf0000380455" ext-link-type="uri">https://unesdoc.unesco.org/ark:/48223/pf0000380455</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>19 February 2022</date-in-citation>).</mixed-citation></ref><ref id="R17"><label>17.</label><mixed-citation publication-type="book"><collab>Group of Twenty</collab>. <source>G20 Ministerial Statement on Trade and Digital Economy</source>. <publisher-loc>Japan</publisher-loc>: <comment>G20</comment>, <year>2019</year>. <comment><ext-link xlink:href="https://www.mofa.go.jp/files/000486596.pdf" ext-link-type="uri">https://www.mofa.go.jp/files/000486596.pdf</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>19 February 2022</date-in-citation>).</mixed-citation></ref><ref id="R18"><label>18.</label><mixed-citation publication-type="other"><collab>South Africa</collab>. <source>Medicines and Related Substances Act No. 101 of 1965</source>.</mixed-citation></ref><ref id="R19"><label>19.</label><mixed-citation publication-type="book"><name><surname>Donelly</surname><given-names>D</given-names></name>. <source>AI in healthcare in South Africa: Dusty-Lee Donnelly</source>. <publisher-loc>Durban</publisher-loc>: <publisher-name>UKZN</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="https://www.youtube.com/watch?v=W32ga8-UynI" ext-link-type="uri">https://www.youtube.com/watch?v=W32ga8-UynI</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>14 October 2021</date-in-citation>).</mixed-citation></ref><ref id="R20"><label>20.</label><mixed-citation publication-type="book"><collab>US Food &#x00026; Drug Administration</collab>. <source>Proposed regulatory framework for modifications to artificial intelligence/machine learning (AI/ML)-based software as a medical device (SaMD) &#x02013; discussion paper and request for feedback</source>. <publisher-loc>Silver Spring: FDA</publisher-loc>, <year>2019</year>.</mixed-citation></ref><ref id="R21"><label>21.</label><mixed-citation publication-type="book"><name><surname>Arowosegbe</surname><given-names>J</given-names></name>. <source>AI in healthcare in South Africa: Jacob Arowosegbe</source>. <publisher-loc>Durban</publisher-loc>: <publisher-name>UKZN</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="https://www.youtube.com/watch?v=onuZqEvfw6M" ext-link-type="uri">https://www.youtube.com/watch?v=onuZqEvfw6M</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>14 October 2021</date-in-citation>).</mixed-citation></ref><ref id="R22"><label>22.</label><mixed-citation publication-type="book"><name><surname>Naidoo</surname><given-names>M</given-names></name>. <source>AI in healthcare in South Africa: Meshandren Naidoo</source>. <publisher-loc>Durban</publisher-loc>: <publisher-name>UKZN</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="https://www.youtube.com/watch?v=4bwuFNh6nLU" ext-link-type="uri">https://www.youtube.com/watch?v=4bwuFNh6nLU</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>14 October 2021</date-in-citation>).</mixed-citation></ref><ref id="R23"><label>23.</label><mixed-citation publication-type="webpage"><collab>Access Partnership</collab>. <source>Artificial intelligence for Africa: An opportunity for growth, development and democratisation</source>. <year>2018</year>. <comment><ext-link xlink:href="https://www.accesspartnership.com/artificial-intelligence-for-africa-an-opportunity-for-growth-development-anddemocratisation/" ext-link-type="uri">https://www.accesspartnership.com/artificial-intelligence-for-africa-an-opportunity-for-growth-development-anddemocratisation/</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>30 September 2021</date-in-citation>).</mixed-citation></ref><ref id="R24"><label>24.</label><mixed-citation publication-type="webpage"><collab>Centre for Data Ethics and Innovation</collab>. <source>Introduction to the Centre for Data Ethics and Innovation</source>. Page <fpage>8</fpage>. <comment><ext-link xlink:href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/973932/CDEI_Introduction-booklet_V2.pdf" ext-link-type="uri">https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/973932/CDEI_Introduction-booklet_V2.pdf</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>22 September 2021</date-in-citation>).</mixed-citation></ref><ref id="R25"><label>25.</label><mixed-citation publication-type="book"><collab>National Department of Communications and Digital Technologies</collab>. <source>Summary report &#x00026; recommendations presented by the Presidential Commission on the Fourth Industrial Revolution</source>. <publisher-loc>Pretoria</publisher-loc>: <publisher-name>Government Gazette No. 42388</publisher-name>:<fpage>43834</fpage>. <year>2019</year>.</mixed-citation></ref><ref id="R26"><label>26.</label><mixed-citation publication-type="book"><collab>World Health Organization</collab>. <source>Health Workforce. Geneva</source>: <publisher-name>WHO</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="https://www.who.int/health-topics/health-workforce#tab=tab_1" ext-link-type="uri">https://www.who.int/health-topics/health-workforce#tab=tab_1</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>2 October 2021</date-in-citation>).</mixed-citation></ref><ref id="R27"><label>27.</label><mixed-citation publication-type="book"><collab>World Health Organization</collab>. <source>Ethics and governance of artificial intelligence for health: WHO guidance</source>. <publisher-loc>Geneva</publisher-loc>: <publisher-name>WHO</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="https://www.who.int/publications/i/item/9789240029200" ext-link-type="uri">https://www.who.int/publications/i/item/9789240029200</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>30 September 2021</date-in-citation>).</mixed-citation></ref><ref id="R28"><label>28.</label><mixed-citation publication-type="book"><collab>World Health Organization</collab>. <source>Ethics and governance of artificial intelligence (AI) in global health background document for WHO</source>. <publisher-loc>Geneva</publisher-loc>: <publisher-name>WHO</publisher-name>, <year>2020</year>.</mixed-citation></ref><ref id="R29"><label>29.</label><mixed-citation publication-type="book"><name><surname>Hickok</surname><given-names>E</given-names></name>, <name><surname>Mohanda</surname><given-names>S</given-names></name>, <name><surname>Barooah</surname><given-names>SP</given-names></name>. <source>The AI Task Force Report &#x02013; The first steps towards India&#x02019;s AI framework</source>. <publisher-loc>Bengaluru</publisher-loc>: <publisher-name>The Centre for Internet and Society</publisher-name>, <year>2018</year>. <comment><ext-link xlink:href="https://cis-india.org/internet-governance/blog/the-ai-task-force-report-the-first-steps-towards-indias-ai-framework" ext-link-type="uri">https://cis-india.org/internet-governance/blog/the-ai-task-force-report-the-first-steps-towards-indias-ai-framework</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>23 September 2021</date-in-citation>).</mixed-citation></ref><ref id="R30"><label>30.</label><mixed-citation publication-type="journal"><name><surname>Thaldar</surname><given-names>DW</given-names></name>, <name><surname>Naidoo</surname><given-names>M</given-names></name>. <article-title>AI inventorship: The right decision?</article-title>
<source>S Afr J Sci</source>
<year>2021</year>;<volume>117</volume>:<fpage>11</fpage>&#x02013;<lpage>12</lpage>:<comment>12509.</comment>
<pub-id pub-id-type="doi">10.17159/sajs.2021/12509</pub-id> (<comment>accessed</comment>
<date-in-citation>29 November 2021</date-in-citation>).</mixed-citation></ref><ref id="R31"><label>31.</label><mixed-citation publication-type="journal"><name><surname>Mokhatla</surname><given-names>Dikoko v.</given-names></name> [<comment>2006</comment>] <source>ZACC</source>
<volume>10</volume>, <year>2006</year> (<issue>6</issue>) <comment>SA 235 (CC) para 113.</comment></mixed-citation></ref><ref id="R32"><label>32.</label><mixed-citation publication-type="other"><collab>South Africa</collab>. <source>Labour Relations Act No. 66 of 1995</source>.</mixed-citation></ref><ref id="R33"><label>33.</label><mixed-citation publication-type="other"><collab>South Africa</collab>. <source>Promotion of National Unity and Reconciliation Act No. 34 of 1995</source>.</mixed-citation></ref><ref id="R34"><label>34.</label><mixed-citation publication-type="other"><collab>South Africa</collab>. <source>Road Accident Fund Act No. 56 of 1996</source>.</mixed-citation></ref><ref id="R35"><label>35.</label><mixed-citation publication-type="book"><collab>Commission for Conciliation, Mediation and Arbitration</collab>. <source>About us</source>. <publisher-loc>Johannesburg</publisher-loc>: <publisher-name>CCMA</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="https://ccmarecovery.syncrony.com/About-Us" ext-link-type="uri">https://ccmarecovery.syncrony.com/About-Us</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>27 October 2021</date-in-citation>).</mixed-citation></ref><ref id="R36"><label>36.</label><mixed-citation publication-type="book"><collab>Apartheid Museum</collab>. <source>The Truth and Reconciliation Committee (TRC)</source>. <publisher-loc>Johannesburg</publisher-loc>: <publisher-name>Apartheid Museum</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="https://www.apartheidmuseum.org/exhibitions/the-truth-and-reconciliation-commission-trc" ext-link-type="uri">https://www.apartheidmuseum.org/exhibitions/the-truth-and-reconciliation-commission-trc</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>5 October 2021</date-in-citation>).</mixed-citation></ref><ref id="R37"><label>37.</label><mixed-citation publication-type="book"><collab>Road Accident Fund</collab>. <source>Mandate</source>. <publisher-loc>Centurion</publisher-loc>: <publisher-name>RAF</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="http://www.raf.co.za/About-Us/Pages/profile.aspx" ext-link-type="uri">http://www.raf.co.za/About-Us/Pages/profile.aspx</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>27 October 2021</date-in-citation>).</mixed-citation></ref><ref id="R38"><label>38.</label><mixed-citation publication-type="book"><collab>European Parliament</collab>. <source>Civil Liability Regime for Artificial Intelligence</source>. <publisher-loc>Strasbourg</publisher-loc>: <publisher-name>European Parliament</publisher-name>, <year>2021</year>. <comment><ext-link xlink:href="https://www.europarl.eu/doceo/document/TA-9-2020-0276_EN.html" ext-link-type="uri">https://www.europarl.eu/doceo/document/TA-9-2020-0276_EN.html</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>27 October 2021</date-in-citation>).</mixed-citation></ref><ref id="R39"><label>39.</label><mixed-citation publication-type="journal"><name><surname>Graham</surname><given-names>SJH</given-names></name>, <name><surname>Merges</surname><given-names>RP</given-names></name>, <name><surname>Samuelson</surname><given-names>P</given-names></name>, <name><surname>Sichelman</surname><given-names>T</given-names></name>. <article-title>High technology entrepreneurs and the patent system: Results of the 2008 Berkeley patent survey</article-title>. <source>Berkeley Technol Law J</source>
<year>2009</year>;<volume>24</volume>(<issue>4</issue>):<fpage>1256</fpage>&#x02013;<lpage>1328</lpage>. <pub-id pub-id-type="doi">10.2139/ssrn.1429049</pub-id> (<comment>accessed</comment>
<date-in-citation>15 February 2022</date-in-citation>).</mixed-citation></ref><ref id="R40"><label>40.</label><mixed-citation publication-type="book"><collab>South African Department of Science and Technology</collab>. <source>White paper on science, technology and innovation</source>. <publisher-loc>Pretoria</publisher-loc>: <publisher-name>DST</publisher-name>, <year>2019</year>. <comment><ext-link xlink:href="https://www.gov.za/sites/default/files/gcis_document/201912/white-paper-science-technology-and-innovation.pdf" ext-link-type="uri">https://www.gov.za/sites/default/files/gcis_document/201912/white-paper-science-technology-and-innovation.pdf</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>15 February 2022</date-in-citation>).</mixed-citation></ref><ref id="R41"><label>41.</label><mixed-citation publication-type="journal"><name><surname>Jordaan</surname><given-names>DW</given-names></name>. <article-title>Biotech innovation in South Africa: Twenty years in review</article-title>. <source>Biotechnology Law Report</source>
<year>2016</year>;<volume>35</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1089/blr.2016.29000.dwj</pub-id> (<comment>accessed</comment>
<date-in-citation>15 February 2022</date-in-citation>).</mixed-citation></ref><ref id="R42"><label>42.</label><mixed-citation publication-type="webpage"><collab>National Department of Health, South Africa</collab>. <source>National Digital Health Strategy for South Africa 2019 &#x02013; 2024</source>. <comment><ext-link xlink:href="https://www.health.gov.za/wp-content/uploads/2020/11/national-digital-strategy-for-south-africa-2019-2024-b.pdf" ext-link-type="uri">https://www.health.gov.za/wp-content/uploads/2020/11/national-digital-strategy-for-south-africa-2019-2024-b.pdf</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>19 February 2022</date-in-citation>).</mixed-citation></ref><ref id="R43"><label>43.</label><mixed-citation publication-type="webpage"><collab>European Union</collab>. <source>EU Declaration on Cooperation on Artificial Intelligence</source>. <year>2018</year>. <comment><ext-link xlink:href="https://ec.europa.eu/jrc/communities/en/node/1286/document/eu-declaration-cooperation-artificial-intelligence" ext-link-type="uri">https://ec.europa.eu/jrc/communities/en/node/1286/document/eu-declaration-cooperation-artificial-intelligence</ext-link></comment> (<comment>accessed</comment>
<date-in-citation>2 October 2021</date-in-citation>).</mixed-citation></ref></ref-list></back><floats-group><table-wrap position="float" id="T1" orientation="landscape"><label>Table 1.</label><caption><p id="P42">Regulatory challenges and recommendations for artificial intelligence (AI) in healthcare</p></caption><table frame="above" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" valign="middle" rowspan="1" colspan="1">Challenges</th><th align="left" valign="middle" rowspan="1" colspan="1">Recommendations</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Restrictive definition of a medical device</td><td align="left" valign="top" rowspan="1" colspan="1">Widen the ambit of the medical device definition to allow for general AI software used in a healthcare setting to be brought under the regulatory framework of the Act</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Single-stage regulatory review mechanism</td><td align="left" valign="top" rowspan="1" colspan="1">Develop a new total product lifecycle regulatory oversight mechanism.</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Data and algorithmic bias</td><td align="left" valign="top" rowspan="1" colspan="1">Establish an institution which deals with ethical issues related to AI, including the quality of input data to AI processes</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Displacement and deskilling of workforce</td><td align="left" valign="top" rowspan="1" colspan="1">Initiate a national education and reskilling programme for the healthcare workforce</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Imposition of liability</td><td align="left" valign="top" rowspan="1" colspan="1">Statutory intervention to exclude common-law delictual liability for harm caused by AI in healthcare, and establish a specialised reconciliation forum in its stead, coupled with insurance-backed strict liability to ensure adequate victim compensation</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Lack of AI innovation and development</td><td align="left" valign="top" rowspan="1" colspan="1">Establish a public-sector health data institution working in tandem with the patient electronic health record system to incentivise development of AI for healthcare in South Africa</td></tr></tbody></table></table-wrap></floats-group></article>
